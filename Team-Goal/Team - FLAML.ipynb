{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML - Team Goal\n",
    "\n",
    "This notebook is used for the appliation of ML algorithms to the Principal Components from the Ethereum, Credit Card, and Insurance datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flaml\n",
    "from flaml import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71250, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.006815</td>\n",
       "      <td>-2.169782</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.467598</td>\n",
       "      <td>-0.327913</td>\n",
       "      <td>0.751913</td>\n",
       "      <td>-0.521793</td>\n",
       "      <td>-0.761362</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.315258</td>\n",
       "      <td>-0.054779</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>1.587008e-17</td>\n",
       "      <td>-0.028777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.352242</td>\n",
       "      <td>-1.128665</td>\n",
       "      <td>-1.880299</td>\n",
       "      <td>0.636689</td>\n",
       "      <td>-0.067591</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>-0.728717</td>\n",
       "      <td>0.883459</td>\n",
       "      <td>-0.048290</td>\n",
       "      <td>0.590403</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>-1.502062e-16</td>\n",
       "      <td>-0.035048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.678475</td>\n",
       "      <td>-2.004593</td>\n",
       "      <td>-0.426661</td>\n",
       "      <td>0.696365</td>\n",
       "      <td>-0.140810</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-0.329805</td>\n",
       "      <td>-0.819126</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>-0.011513</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>-2.395613e-17</td>\n",
       "      <td>-0.035048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.505144</td>\n",
       "      <td>-1.625462</td>\n",
       "      <td>-1.122661</td>\n",
       "      <td>0.626570</td>\n",
       "      <td>-0.059864</td>\n",
       "      <td>0.908407</td>\n",
       "      <td>-0.226611</td>\n",
       "      <td>-0.791670</td>\n",
       "      <td>0.777155</td>\n",
       "      <td>-0.030135</td>\n",
       "      <td>-0.182153</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>5.063698e-17</td>\n",
       "      <td>-0.035048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.487477</td>\n",
       "      <td>-1.586732</td>\n",
       "      <td>-1.193951</td>\n",
       "      <td>0.619052</td>\n",
       "      <td>-0.051163</td>\n",
       "      <td>0.917079</td>\n",
       "      <td>-0.216019</td>\n",
       "      <td>-0.788997</td>\n",
       "      <td>0.783427</td>\n",
       "      <td>-0.032049</td>\n",
       "      <td>-0.205875</td>\n",
       "      <td>0.033085</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>5.931060e-17</td>\n",
       "      <td>-0.035048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -2.006815 -2.169782  0.146400  0.467598 -0.327913  0.751913 -0.521793   \n",
       "1 -1.352242 -1.128665 -1.880299  0.636689 -0.067591  0.997769 -0.122053   \n",
       "2 -1.678475 -2.004593 -0.426661  0.696365 -0.140810  0.824183 -0.329805   \n",
       "3 -1.505144 -1.625462 -1.122661  0.626570 -0.059864  0.908407 -0.226611   \n",
       "4 -1.487477 -1.586732 -1.193951  0.619052 -0.051163  0.917079 -0.216019   \n",
       "\n",
       "          7         8         9        10        11        12            13  \\\n",
       "0 -0.761362  0.788030  0.315258 -0.054779  0.023103 -0.001547  1.587008e-17   \n",
       "1 -0.728717  0.883459 -0.048290  0.590403  0.036177 -0.002929 -1.502062e-16   \n",
       "2 -0.819126  0.714460 -0.011513  0.009796  0.033345 -0.001582 -2.395613e-17   \n",
       "3 -0.791670  0.777155 -0.030135 -0.182153  0.033123 -0.000876  5.063698e-17   \n",
       "4 -0.788997  0.783427 -0.032049 -0.205875  0.033085 -0.000792  5.931060e-17   \n",
       "\n",
       "      value  \n",
       "0 -0.028777  \n",
       "1 -0.035048  \n",
       "2 -0.035048  \n",
       "3 -0.035048  \n",
       "4 -0.035048  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data for modeling\n",
    "data = pd.read_pickle('Data/principal_components.pkl')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71245</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71246</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71247</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71248</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71249</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71250 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "71245  1\n",
       "71246  1\n",
       "71247  1\n",
       "71248  1\n",
       "71249  1\n",
       "\n",
       "[71250 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a single column indicating if a transaction is fraud as our target\n",
    "to_scam = np.array(pd.read_pickle('Data/to_scam.pkl'))\n",
    "from_scam = np.array(pd.read_pickle('Data/from_scam.pkl'))\n",
    "\n",
    "temp = to_scam + from_scam\n",
    "scam =[]\n",
    "for i in temp:\n",
    "    if i==0:\n",
    "        scam.append(0)\n",
    "    else:\n",
    "        scam.append(1)\n",
    "target = pd.DataFrame(scam)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-05 12:31:32] {2055} INFO - task = classification\n",
      "[flaml.automl: 04-05 12:31:32] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 04-05 12:31:32] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 04-05 12:31:32] {2142} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl: 04-05 12:31:32] {2200} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'rf']\n",
      "[flaml.automl: 04-05 12:31:32] {2453} INFO - iteration 0, current learner lgbm\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[flaml.automl: 04-05 12:31:33] {2569} INFO - Estimated sufficient time budget=39170s. Estimated necessary time budget=39s.\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.7s,\testimator lgbm's best error=0.3624,\tbest estimator lgbm's best error=0.3624\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.7s,\testimator lgbm's best error=0.3624,\tbest estimator lgbm's best error=0.3624\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.7s,\testimator lgbm's best error=0.2655,\tbest estimator lgbm's best error=0.2655\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.1759,\tbest estimator lgbm's best error=0.1759\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.1759,\tbest estimator lgbm's best error=0.1759\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.1759,\tbest estimator lgbm's best error=0.1759\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.1759,\tbest estimator lgbm's best error=0.1759\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.1759,\tbest estimator lgbm's best error=0.1759\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 0.9s,\testimator lgbm's best error=0.1736,\tbest estimator lgbm's best error=0.1736\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 1.0s,\testimator lgbm's best error=0.1736,\tbest estimator lgbm's best error=0.1736\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 1.1s,\testimator lgbm's best error=0.1052,\tbest estimator lgbm's best error=0.1052\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:33] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.1052,\tbest estimator lgbm's best error=0.1052\n",
      "[flaml.automl: 04-05 12:31:33] {2453} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:34] {2621} INFO -  at 1.5s,\testimator lgbm's best error=0.1052,\tbest estimator lgbm's best error=0.1052\n",
      "[flaml.automl: 04-05 12:31:34] {2453} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:34] {2621} INFO -  at 1.6s,\testimator lgbm's best error=0.1052,\tbest estimator lgbm's best error=0.1052\n",
      "[flaml.automl: 04-05 12:31:34] {2453} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:34] {2621} INFO -  at 1.8s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:34] {2453} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:34] {2621} INFO -  at 2.2s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:34] {2453} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:34] {2621} INFO -  at 2.3s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:34] {2453} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 2.8s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 2.9s,\testimator xgboost's best error=0.4828,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 2.9s,\testimator xgboost's best error=0.4828,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 2.9s,\testimator xgboost's best error=0.3130,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 2.9s,\testimator xgboost's best error=0.2034,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.0s,\testimator xgboost's best error=0.2034,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.0s,\testimator xgboost's best error=0.2034,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.0s,\testimator xgboost's best error=0.1790,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.1s,\testimator xgboost's best error=0.1669,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.1s,\testimator xgboost's best error=0.1669,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.2s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:35] {2621} INFO -  at 3.3s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:35] {2453} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.4s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.4s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.5s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.5s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.6s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.6s,\testimator xgboost's best error=0.1438,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.7s,\testimator xgboost's best error=0.1438,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.8s,\testimator xgboost's best error=0.1430,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 3.9s,\testimator xgboost's best error=0.1430,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:36] {2621} INFO -  at 4.3s,\testimator xgboost's best error=0.1407,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:36] {2453} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:37] {2621} INFO -  at 4.4s,\testimator xgboost's best error=0.1407,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:37] {2453} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:37] {2621} INFO -  at 4.8s,\testimator lgbm's best error=0.1048,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:37] {2453} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:39] {2621} INFO -  at 6.4s,\testimator xgboost's best error=0.1407,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:39] {2453} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 04-05 12:31:39] {2621} INFO -  at 6.7s,\testimator rf's best error=0.2896,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:39] {2453} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 04-05 12:31:39] {2621} INFO -  at 7.1s,\testimator rf's best error=0.2134,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:39] {2453} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 04-05 12:31:40] {2621} INFO -  at 7.4s,\testimator rf's best error=0.2134,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:40] {2453} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:40] {2621} INFO -  at 7.7s,\testimator xgboost's best error=0.1407,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:40] {2453} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 04-05 12:31:40] {2621} INFO -  at 8.1s,\testimator rf's best error=0.2134,\tbest estimator lgbm's best error=0.1048\n",
      "[flaml.automl: 04-05 12:31:40] {2453} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:41] {2621} INFO -  at 8.4s,\testimator lgbm's best error=0.0962,\tbest estimator lgbm's best error=0.0962\n",
      "[flaml.automl: 04-05 12:31:41] {2453} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:42] {2621} INFO -  at 9.6s,\testimator xgboost's best error=0.0914,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:42] {2453} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 04-05 12:31:42] {2621} INFO -  at 9.9s,\testimator rf's best error=0.1844,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:42] {2453} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:42] {2621} INFO -  at 10.0s,\testimator lgbm's best error=0.0962,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:42] {2453} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:43] {2621} INFO -  at 10.4s,\testimator lgbm's best error=0.0962,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:43] {2453} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:43] {2621} INFO -  at 10.7s,\testimator lgbm's best error=0.0962,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:43] {2453} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:44] {2621} INFO -  at 11.4s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:44] {2453} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 04-05 12:31:44] {2621} INFO -  at 11.8s,\testimator rf's best error=0.1844,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:44] {2453} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:44] {2621} INFO -  at 12.0s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:44] {2453} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:45] {2621} INFO -  at 13.0s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:45] {2453} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:46] {2621} INFO -  at 13.7s,\testimator xgboost's best error=0.0914,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:46] {2453} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:46] {2621} INFO -  at 13.9s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:46] {2453} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 04-05 12:31:46] {2621} INFO -  at 14.2s,\testimator rf's best error=0.1759,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:46] {2453} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:46] {2621} INFO -  at 14.4s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:46] {2453} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 04-05 12:31:47] {2621} INFO -  at 14.8s,\testimator rf's best error=0.1617,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:47] {2453} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 04-05 12:31:47] {2621} INFO -  at 15.1s,\testimator rf's best error=0.1617,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:47] {2453} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:50] {2621} INFO -  at 17.4s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:50] {2453} INFO - iteration 64, current learner rf\n",
      "[flaml.automl: 04-05 12:31:50] {2621} INFO -  at 17.8s,\testimator rf's best error=0.1617,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:50] {2453} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 04-05 12:31:50] {2621} INFO -  at 18.3s,\testimator rf's best error=0.1617,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:50] {2453} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 04-05 12:31:51] {2621} INFO -  at 18.7s,\testimator rf's best error=0.1617,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:51] {2453} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:51] {2621} INFO -  at 19.0s,\testimator lgbm's best error=0.0943,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:51] {2453} INFO - iteration 68, current learner rf\n",
      "[flaml.automl: 04-05 12:31:52] {2621} INFO -  at 19.5s,\testimator rf's best error=0.1478,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:52] {2453} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 04-05 12:31:52] {2621} INFO -  at 19.9s,\testimator rf's best error=0.1478,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:52] {2453} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 04-05 12:31:53] {2621} INFO -  at 20.4s,\testimator rf's best error=0.1478,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:53] {2453} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 04-05 12:31:53] {2621} INFO -  at 20.9s,\testimator rf's best error=0.1380,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:53] {2453} INFO - iteration 72, current learner rf\n",
      "[flaml.automl: 04-05 12:31:53] {2621} INFO -  at 21.3s,\testimator rf's best error=0.1380,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:53] {2453} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 04-05 12:31:54] {2621} INFO -  at 21.8s,\testimator rf's best error=0.1380,\tbest estimator xgboost's best error=0.0914\n",
      "[flaml.automl: 04-05 12:31:54] {2453} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:55] {2621} INFO -  at 22.5s,\testimator lgbm's best error=0.0868,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:55] {2453} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:55] {2621} INFO -  at 22.9s,\testimator lgbm's best error=0.0868,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:55] {2453} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 04-05 12:31:56] {2621} INFO -  at 23.6s,\testimator rf's best error=0.1298,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:56] {2453} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:58] {2621} INFO -  at 25.6s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:58] {2453} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 04-05 12:31:58] {2621} INFO -  at 26.2s,\testimator lgbm's best error=0.0868,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:58] {2453} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 04-05 12:31:59] {2621} INFO -  at 26.8s,\testimator rf's best error=0.1298,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:59] {2453} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 04-05 12:31:59] {2621} INFO -  at 27.1s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:31:59] {2453} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 04-05 12:32:00] {2621} INFO -  at 27.5s,\testimator rf's best error=0.1298,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:00] {2453} INFO - iteration 82, current learner rf\n",
      "[flaml.automl: 04-05 12:32:00] {2621} INFO -  at 28.1s,\testimator rf's best error=0.1264,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:00] {2453} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 04-05 12:32:01] {2621} INFO -  at 28.7s,\testimator rf's best error=0.1264,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:01] {2453} INFO - iteration 84, current learner rf\n",
      "[flaml.automl: 04-05 12:32:02] {2621} INFO -  at 29.5s,\testimator rf's best error=0.1264,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:02] {2453} INFO - iteration 85, current learner rf\n",
      "[flaml.automl: 04-05 12:32:02] {2621} INFO -  at 30.0s,\testimator rf's best error=0.1264,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:02] {2453} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 04-05 12:32:09] {2621} INFO -  at 36.5s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:09] {2453} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 04-05 12:32:10] {2621} INFO -  at 37.4s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:10] {2453} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 04-05 12:32:10] {2621} INFO -  at 38.0s,\testimator rf's best error=0.1264,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:10] {2453} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 04-05 12:32:14] {2621} INFO -  at 41.8s,\testimator rf's best error=0.1134,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:14] {2453} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 04-05 12:32:19] {2621} INFO -  at 46.5s,\testimator rf's best error=0.1134,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:19] {2453} INFO - iteration 91, current learner rf\n",
      "[flaml.automl: 04-05 12:32:21] {2621} INFO -  at 48.8s,\testimator rf's best error=0.1062,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:21] {2453} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 04-05 12:32:23] {2621} INFO -  at 50.8s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:23] {2453} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 04-05 12:32:27] {2621} INFO -  at 54.6s,\testimator lgbm's best error=0.0868,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:27] {2453} INFO - iteration 94, current learner rf\n",
      "[flaml.automl: 04-05 12:32:29] {2621} INFO -  at 56.5s,\testimator rf's best error=0.1062,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:29] {2453} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl: 04-05 12:32:29] {2621} INFO -  at 56.6s,\testimator lgbm's best error=0.0868,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:29] {2453} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl: 04-05 12:32:29] {2621} INFO -  at 56.9s,\testimator xgboost's best error=0.0914,\tbest estimator lgbm's best error=0.0868\n",
      "[flaml.automl: 04-05 12:32:29] {2453} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl: 04-05 12:32:31] {2621} INFO -  at 58.4s,\testimator lgbm's best error=0.0864,\tbest estimator lgbm's best error=0.0864\n",
      "[flaml.automl: 04-05 12:32:31] {2453} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl: 04-05 12:32:31] {2621} INFO -  at 58.9s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
      "[flaml.automl: 04-05 12:32:31] {2453} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl: 04-05 12:32:32] {2621} INFO -  at 60.0s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
      "[flaml.automl: 04-05 12:32:32] {2769} INFO - [('lgbm', <flaml.model.LGBMEstimator object at 0x7f7e3ba43f10>), ('xgboost', <flaml.model.XGBoostSklearnEstimator object at 0x7f7e3ba43510>), ('rf', <flaml.model.RandomForestEstimator object at 0x7f7e3ba43a90>)]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "[flaml.automl: 04-05 12:32:53] {2797} INFO - ensemble: StackingClassifier(estimators=[('lgbm',\n",
      "                                <flaml.model.LGBMEstimator object at 0x7f7e3ba43f10>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.model.XGBoostSklearnEstimator object at 0x7f7e3ba43510>),\n",
      "                               ('rf',\n",
      "                                <flaml.model.RandomForestEstimator object at 0x7f7e3ba43a90>)],\n",
      "                   n_jobs=-1, passthrough=True)\n",
      "[flaml.automl: 04-05 12:32:53] {2229} INFO - fit succeeded\n",
      "[flaml.automl: 04-05 12:32:53] {2231} INFO - Time taken to find the best model: 58.945635080337524\n",
      "[flaml.automl: 04-05 12:32:53] {2245} WARNING - Time taken to find the best model is 98% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(np.array(data), np.array(target), task=\"classification\", estimator_list = ['lgbm','xgboost','rf'], metric ='log_loss' , max_iter = 10000, time_budget = None, ensemble= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best configuration of each type of model\n",
    "import pickle\n",
    "\n",
    "eth_xgboost_mod = automl.best_model_for_estimator('xgboost')\n",
    "eth_lgbm_mod = automl.best_model_for_estimator('lgbm')\n",
    "eth_rf_mod = automl.best_model_for_estimator('rf')\n",
    "eth_automl = automl\n",
    "\n",
    "pickle.dump(eth_xgboost_mod, open('Models/eth_xg.pkl','wb'))\n",
    "pickle.dump(eth_lgbm_mod, open('Models/eth_lgbm.pkl','wb'))\n",
    "pickle.dump(eth_rf_mod, open('Models/eth_rf.pkl','wb'))\n",
    "pickle.dump(eth_automl, open('Models/eth_automl.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data for modeling and remove unneeded columns\n",
    "data_credit = pd.read_csv('creditcard.csv')\n",
    "print(data_credit.shape)\n",
    "data_credit.pop('Time')\n",
    "target_class = data_credit.pop('Class')\n",
    "data_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize value column\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler().fit(np.array(data_credit['Amount']).reshape(-1,1))\n",
    "transformed_value = transformer.transform(np.array(data_credit['Amount']).reshape(-1,1)).reshape(1,284807)[0]\n",
    "data_credit['Amount']=transformed_value\n",
    "data_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-05 12:41:22] {2055} INFO - task = classification\n",
      "[flaml.automl: 04-05 12:41:22] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 04-05 12:41:22] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 04-05 12:41:22] {2142} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl: 04-05 12:41:22] {2200} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'rf']\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2569} INFO - Estimated sufficient time budget=8753s. Estimated necessary time budget=9s.\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.4s,\testimator lgbm's best error=0.0076,\tbest estimator lgbm's best error=0.0076\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.5s,\testimator lgbm's best error=0.0076,\tbest estimator lgbm's best error=0.0076\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.5s,\testimator lgbm's best error=0.0056,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.4017,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.6s,\testimator lgbm's best error=0.0056,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.6s,\testimator lgbm's best error=0.0056,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.7s,\testimator lgbm's best error=0.0056,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:22] {2621} INFO -  at 0.7s,\testimator lgbm's best error=0.0056,\tbest estimator lgbm's best error=0.0056\n",
      "[flaml.automl: 04-05 12:41:22] {2453} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 0.8s,\testimator lgbm's best error=0.0052,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.4017,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.1819,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 11, current learner rf\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.2s,\testimator rf's best error=0.0059,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.2s,\testimator xgboost's best error=0.0097,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.3s,\testimator xgboost's best error=0.0097,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.3s,\testimator xgboost's best error=0.0097,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.4s,\testimator lgbm's best error=0.0052,\tbest estimator lgbm's best error=0.0052\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.5s,\testimator xgboost's best error=0.0050,\tbest estimator xgboost's best error=0.0050\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.5s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.6s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.7s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:23] {2621} INFO -  at 1.7s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:23] {2453} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 1.9s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 1.9s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 2.3s,\testimator rf's best error=0.0059,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 24, current learner rf\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 2.6s,\testimator rf's best error=0.0054,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 2.7s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:24] {2621} INFO -  at 2.7s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:24] {2453} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 04-05 12:41:25] {2621} INFO -  at 3.1s,\testimator rf's best error=0.0054,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:25] {2453} INFO - iteration 28, current learner rf\n",
      "[flaml.automl: 04-05 12:41:25] {2621} INFO -  at 3.5s,\testimator rf's best error=0.0054,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:25] {2453} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:25] {2621} INFO -  at 3.6s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:25] {2453} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:26] {2621} INFO -  at 3.9s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:26] {2453} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:26] {2621} INFO -  at 4.0s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:26] {2453} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 04-05 12:41:26] {2621} INFO -  at 4.4s,\testimator rf's best error=0.0054,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 04-05 12:41:26] {2453} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 4.8s,\testimator lgbm's best error=0.0046,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 4.9s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.2s,\testimator rf's best error=0.0054,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.3s,\testimator xgboost's best error=0.0050,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.3s,\testimator xgboost's best error=0.0048,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.4s,\testimator xgboost's best error=0.0048,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.5s,\testimator xgboost's best error=0.0048,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:27] {2621} INFO -  at 5.5s,\testimator xgboost's best error=0.0048,\tbest estimator lgbm's best error=0.0046\n",
      "[flaml.automl: 04-05 12:41:27] {2453} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:28] {2621} INFO -  at 5.9s,\testimator lgbm's best error=0.0036,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:28] {2453} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:28] {2621} INFO -  at 6.0s,\testimator xgboost's best error=0.0048,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:28] {2453} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 04-05 12:41:28] {2621} INFO -  at 6.4s,\testimator rf's best error=0.0048,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:28] {2453} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:28] {2621} INFO -  at 6.5s,\testimator xgboost's best error=0.0045,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:28] {2453} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:29] {2621} INFO -  at 6.9s,\testimator lgbm's best error=0.0036,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:29] {2453} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:29] {2621} INFO -  at 7.0s,\testimator xgboost's best error=0.0045,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:29] {2453} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:29] {2621} INFO -  at 7.4s,\testimator lgbm's best error=0.0036,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:29] {2453} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:29] {2621} INFO -  at 7.5s,\testimator xgboost's best error=0.0043,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:29] {2453} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:29] {2621} INFO -  at 7.7s,\testimator xgboost's best error=0.0042,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:29] {2453} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:30] {2621} INFO -  at 7.8s,\testimator xgboost's best error=0.0042,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:30] {2453} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:30] {2621} INFO -  at 7.9s,\testimator xgboost's best error=0.0042,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:30] {2453} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:30] {2621} INFO -  at 8.4s,\testimator lgbm's best error=0.0036,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:30] {2453} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:31] {2621} INFO -  at 8.8s,\testimator lgbm's best error=0.0036,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:31] {2453} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:31] {2621} INFO -  at 9.1s,\testimator xgboost's best error=0.0042,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:31] {2453} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:31] {2621} INFO -  at 9.2s,\testimator xgboost's best error=0.0042,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:31] {2453} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:32] {2621} INFO -  at 9.8s,\testimator xgboost's best error=0.0041,\tbest estimator lgbm's best error=0.0036\n",
      "[flaml.automl: 04-05 12:41:32] {2453} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:32] {2621} INFO -  at 10.4s,\testimator xgboost's best error=0.0035,\tbest estimator xgboost's best error=0.0035\n",
      "[flaml.automl: 04-05 12:41:32] {2453} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:32] {2621} INFO -  at 10.8s,\testimator lgbm's best error=0.0036,\tbest estimator xgboost's best error=0.0035\n",
      "[flaml.automl: 04-05 12:41:32] {2453} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:33] {2621} INFO -  at 11.4s,\testimator xgboost's best error=0.0035,\tbest estimator xgboost's best error=0.0035\n",
      "[flaml.automl: 04-05 12:41:33] {2453} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:34] {2621} INFO -  at 11.9s,\testimator lgbm's best error=0.0034,\tbest estimator lgbm's best error=0.0034\n",
      "[flaml.automl: 04-05 12:41:34] {2453} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:34] {2621} INFO -  at 12.2s,\testimator xgboost's best error=0.0035,\tbest estimator lgbm's best error=0.0034\n",
      "[flaml.automl: 04-05 12:41:34] {2453} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 04-05 12:41:34] {2621} INFO -  at 12.7s,\testimator rf's best error=0.0048,\tbest estimator lgbm's best error=0.0034\n",
      "[flaml.automl: 04-05 12:41:34] {2453} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:35] {2621} INFO -  at 13.2s,\testimator lgbm's best error=0.0034,\tbest estimator lgbm's best error=0.0034\n",
      "[flaml.automl: 04-05 12:41:35] {2453} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:35] {2621} INFO -  at 13.7s,\testimator lgbm's best error=0.0034,\tbest estimator lgbm's best error=0.0034\n",
      "[flaml.automl: 04-05 12:41:35] {2453} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:36] {2621} INFO -  at 14.6s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
      "[flaml.automl: 04-05 12:41:36] {2453} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:37] {2621} INFO -  at 15.2s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0033\n",
      "[flaml.automl: 04-05 12:41:37] {2453} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:38] {2621} INFO -  at 15.8s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0033\n",
      "[flaml.automl: 04-05 12:41:38] {2453} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:39] {2621} INFO -  at 17.0s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:39] {2453} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 04-05 12:41:39] {2621} INFO -  at 17.4s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:39] {2453} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:41] {2621} INFO -  at 19.3s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:41] {2453} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 04-05 12:41:42] {2621} INFO -  at 20.0s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:42] {2453} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:43] {2621} INFO -  at 21.6s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:43] {2453} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 04-05 12:41:45] {2621} INFO -  at 23.1s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:45] {2453} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:45] {2621} INFO -  at 23.6s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:45] {2453} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:46] {2621} INFO -  at 24.2s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:46] {2453} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 04-05 12:41:47] {2621} INFO -  at 25.2s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:47] {2453} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:48] {2621} INFO -  at 26.2s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:48] {2453} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:48] {2621} INFO -  at 26.7s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:48] {2453} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 04-05 12:41:51] {2621} INFO -  at 29.5s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:51] {2453} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl: 04-05 12:41:52] {2621} INFO -  at 30.0s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:52] {2453} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:53] {2621} INFO -  at 31.0s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:53] {2453} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl: 04-05 12:41:59] {2621} INFO -  at 37.2s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:41:59] {2453} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 04-05 12:42:00] {2621} INFO -  at 38.7s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:00] {2453} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl: 04-05 12:42:01] {2621} INFO -  at 39.2s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:01] {2453} INFO - iteration 85, current learner rf\n",
      "[flaml.automl: 04-05 12:42:03] {2621} INFO -  at 40.9s,\testimator rf's best error=0.0048,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:03] {2453} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl: 04-05 12:42:04] {2621} INFO -  at 42.0s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:04] {2453} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl: 04-05 12:42:04] {2621} INFO -  at 42.4s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:04] {2453} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 04-05 12:42:07] {2621} INFO -  at 45.4s,\testimator rf's best error=0.0042,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:07] {2453} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl: 04-05 12:42:08] {2621} INFO -  at 46.7s,\testimator xgboost's best error=0.0032,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:08] {2453} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 04-05 12:42:11] {2621} INFO -  at 48.8s,\testimator rf's best error=0.0042,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:11] {2453} INFO - iteration 91, current learner rf\n",
      "[flaml.automl: 04-05 12:42:13] {2621} INFO -  at 51.3s,\testimator rf's best error=0.0042,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:13] {2453} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 04-05 12:42:17] {2621} INFO -  at 55.1s,\testimator rf's best error=0.0042,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:17] {2453} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 04-05 12:42:18] {2621} INFO -  at 56.0s,\testimator lgbm's best error=0.0034,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:18] {2453} INFO - iteration 94, current learner rf\n",
      "[flaml.automl: 04-05 12:42:22] {2621} INFO -  at 60.4s,\testimator rf's best error=0.0039,\tbest estimator xgboost's best error=0.0032\n",
      "[flaml.automl: 04-05 12:42:22] {2769} INFO - [('xgboost', <flaml.model.XGBoostSklearnEstimator object at 0x7f7e3e185490>), ('lgbm', <flaml.model.LGBMEstimator object at 0x7f7e3e027190>), ('rf', <flaml.model.RandomForestEstimator object at 0x7f7e3ba43250>)]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "[flaml.automl: 04-05 12:42:50] {2797} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.model.XGBoostSklearnEstimator object at 0x7f7e3e185490>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.model.LGBMEstimator object at 0x7f7e3e027190>),\n",
      "                               ('rf',\n",
      "                                <flaml.model.RandomForestEstimator object at 0x7f7e3ba43250>)],\n",
      "                   n_jobs=-1, passthrough=True)\n",
      "[flaml.automl: 04-05 12:42:50] {2229} INFO - fit succeeded\n",
      "[flaml.automl: 04-05 12:42:50] {2231} INFO - Time taken to find the best model: 17.049474000930786\n"
     ]
    }
   ],
   "source": [
    "automl_credit = AutoML()\n",
    "automl_credit.fit(np.array(data_credit), np.array(target_class), task=\"classification\", estimator_list = ['lgbm','xgboost','rf'], metric ='log_loss' , max_iter = 10000, time_budget = None, ensemble= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best configuration of each type of model\n",
    "credit_xgboost_mod = automl_credit.best_model_for_estimator('xgboost')\n",
    "credit_lgbm_mod = automl_credit.best_model_for_estimator('lgbm')\n",
    "credit_rf_mod = automl_credit.best_model_for_estimator('rf')\n",
    "\n",
    "pickle.dump(credit_xgboost_mod, open('Models/credit_xg.pkl','wb'))\n",
    "pickle.dump(credit_lgbm_mod, open('Models/credit_lgbm.pkl','wb'))\n",
    "pickle.dump(credit_rf_mod, open('Models/credit_rf.pkl','wb'))\n",
    "pickle.dump(automl_credit, open('Models/credit_automl.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data for modeling and remove unneeded columns\n",
    "data_insurance = pd.read_csv('insurance_claims.csv')\n",
    "print(data_insurance.shape)\n",
    "target_class = data_credit.pop('fraud_reported')\n",
    "data_insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the best model configuration for each type of dataset using repeated cross validation. Record the four metrics: F1, Recall, Precision, Roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# import best model configurations\n",
    "eth = pd.read_pickle(r'Models/eth_automl.pkl')\n",
    "credit = pd.read_pickle(r'Models/credit_automl.pkl')\n",
    "#insurance = pd.read_pickle(r'Models/insurance_automl.pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# 5-fold cross validation with 25 repeats\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=25, random_state=1)\n",
    "\n",
    "# read in best ethereum model configuration and compute metrics on cross-validation splits/repetitions\n",
    "eth_mod = pd.read_pickle(r'Models/eth_lgbm.pkl')\n",
    "eth_scores = cross_validate(eth_mod,data,np.ravel(target),scoring=['f1','recall','precision','roc_auc'],cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save average metrics across all splits and repeats\n",
    "eth_f1_mean = np.mean(eth_scores['test_f1'])\n",
    "eth_recall_mean = np.mean(eth_scores['test_recall'])\n",
    "eth_precision_mean = np.mean(eth_scores['test_precision'])\n",
    "eth_roc_mean = np.mean(eth_scores['test_roc_auc'])\n",
    "\n",
    "eth_f1_var = np.var(eth_scores['test_f1'])\n",
    "eth_recall_var = np.var(eth_scores['test_recall'])\n",
    "eth_precision_var = np.var(eth_scores['test_precision'])\n",
    "eth_roc_var = np.var(eth_scores['test_roc_auc'])\n",
    "\n",
    "eth_f1_max = np.max(eth_scores['test_f1'])\n",
    "eth_recall_max = np.max(eth_scores['test_recall'])\n",
    "eth_precision_max = np.max(eth_scores['test_precision'])\n",
    "eth_roc_max = np.max(eth_scores['test_roc_auc'])\n",
    "\n",
    "eth_f1_min = np.min(eth_scores['test_f1'])\n",
    "eth_recall_min = np.min(eth_scores['test_recall'])\n",
    "eth_precision_min = np.min(eth_scores['test_precision'])\n",
    "eth_roc_min = np.min(eth_scores['test_roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation with 25 repeats\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=25, random_state=1)\n",
    "\n",
    "# read in best ethereum model configuration and compute metrics on cross-validation splits/repetitions\n",
    "credit_mod = pd.read_pickle(r'Models/credit_xg.pkl')\n",
    "credit_scores = cross_validate(credit_mod,data_credit,np.ravel(target_class),scoring=['f1','recall','precision','roc_auc'],cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save average metrics across all splits and repeats\n",
    "credit_f1_mean = np.mean(credit_scores['test_f1'])\n",
    "credit_recall_mean = np.mean(credit_scores['test_recall'])\n",
    "credit_precision_mean = np.mean(credit_scores['test_precision'])\n",
    "credit_roc_mean = np.mean(credit_scores['test_roc_auc'])\n",
    "\n",
    "credit_f1_var = np.var(credit_scores['test_f1'])\n",
    "credit_recall_var = np.var(credit_scores['test_recall'])\n",
    "credit_precision_var = np.var(credit_scores['test_precision'])\n",
    "credit_roc_var = np.var(credit_scores['test_roc_auc'])\n",
    "\n",
    "credit_f1_max = np.max(credit_scores['test_f1'])\n",
    "credit_recall_max = np.max(credit_scores['test_recall'])\n",
    "credit_precision_max = np.max(credit_scores['test_precision'])\n",
    "credit_roc_max = np.max(credit_scores['test_roc_auc'])\n",
    "\n",
    "credit_f1_min = np.min(credit_scores['test_f1'])\n",
    "credit_recall_min = np.min(credit_scores['test_recall'])\n",
    "credit_precision_min = np.min(credit_scores['test_precision'])\n",
    "credit_roc_min = np.min(credit_scores['test_roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.926644</td>\n",
       "      <td>0.872837</td>\n",
       "      <td>0.987541</td>\n",
       "      <td>0.986233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.935786</td>\n",
       "      <td>0.890797</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.989159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.919792</td>\n",
       "      <td>0.860667</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.981142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F1    Recall  Precision       Roc\n",
       "Mean      0.926644  0.872837   0.987541  0.986233\n",
       "Variance  0.000009  0.000025   0.000005  0.000002\n",
       "Max       0.935786  0.890797   0.993750  0.989159\n",
       "Min       0.919792  0.860667   0.980392  0.981142"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get results for ethereum data\n",
    "\n",
    "eth_results = pd.DataFrame()\n",
    "eth_results['F1'] = [eth_f1_mean,eth_f1_var,eth_f1_max,eth_f1_min]\n",
    "eth_results['Recall'] = [eth_recall_mean,eth_recall_var,eth_recall_max,eth_recall_min]\n",
    "eth_results['Precision'] = [eth_precision_mean,eth_precision_var,eth_precision_max,eth_precision_min]\n",
    "eth_results['Roc'] = [eth_roc_mean,eth_roc_var,eth_roc_max,eth_roc_min]\n",
    "eth_results.rename(index={0:'Mean',1:'Variance',2:'Max',3:'Min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.862059</td>\n",
       "      <td>0.793792</td>\n",
       "      <td>0.944961</td>\n",
       "      <td>0.980260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.998594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.954890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F1    Recall  Precision       Roc\n",
       "Mean      0.862059  0.793792   0.944961  0.980260\n",
       "Variance  0.000671  0.001690   0.000579  0.000063\n",
       "Max       0.936170  0.897959   0.988764  0.998594\n",
       "Min       0.795455  0.686275   0.880952  0.954890"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get results for credit card data \n",
    "\n",
    "credit_results = pd.DataFrame()\n",
    "credit_results['F1'] = [credit_f1_mean,credit_f1_var,credit_f1_max,credit_f1_min]\n",
    "credit_results['Recall'] = [credit_recall_mean,credit_recall_var,credit_recall_max,credit_recall_min]\n",
    "credit_results['Precision'] = [credit_precision_mean,credit_precision_var,credit_precision_max,credit_precision_min]\n",
    "credit_results['Roc'] = [credit_roc_mean,credit_roc_var,credit_roc_max,credit_roc_min]\n",
    "credit_results.rename(index={0:'Mean',1:'Variance',2:'Max',3:'Min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
