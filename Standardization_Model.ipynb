{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flaml\n",
    "import sklearn.metrics\n",
    "from flaml import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nonce</th>\n",
       "      <th>transaction_index</th>\n",
       "      <th>value</th>\n",
       "      <th>gas</th>\n",
       "      <th>gas_price</th>\n",
       "      <th>input</th>\n",
       "      <th>receipt_gas_used</th>\n",
       "      <th>from_scam</th>\n",
       "      <th>to_scam</th>\n",
       "      <th>months</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.927516</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>1.052132</td>\n",
       "      <td>-0.072464</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54363</td>\n",
       "      <td>-0.230799</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>-0.164294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.047148</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>-0.163040</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54363</td>\n",
       "      <td>-0.230799</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>-0.049980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.047321</td>\n",
       "      <td>-0.284091</td>\n",
       "      <td>-0.163040</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54363</td>\n",
       "      <td>-0.230799</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>0.007177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.047734</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.163040</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54363</td>\n",
       "      <td>-0.230799</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>0.007177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.047800</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>-0.163040</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54363</td>\n",
       "      <td>-0.230799</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>0.007177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nonce  transaction_index     value       gas  gas_price  input  \\\n",
       "0  4.927516          -0.590909  1.052132 -0.072464   0.048111      0   \n",
       "1  3.047148           0.329545 -0.163040  0.797101   0.014304      0   \n",
       "2  3.047321          -0.284091 -0.163040  0.797101   0.014304      0   \n",
       "3  3.047734           0.250000 -0.163040  0.797101   0.014304      0   \n",
       "4  3.047800           0.306818 -0.163040  0.797101   0.014304      0   \n",
       "\n",
       "   receipt_gas_used  from_scam  to_scam   months      days     hours   minutes  \n",
       "0               0.0          0        0  1.54363 -0.230799 -0.934209 -0.164294  \n",
       "1               0.0          0        0  1.54363 -0.230799 -0.934209 -0.049980  \n",
       "2               0.0          0        0  1.54363 -0.230799 -0.934209  0.007177  \n",
       "3               0.0          0        0  1.54363 -0.230799 -0.934209  0.007177  \n",
       "4               0.0          0        0  1.54363 -0.230799 -0.934209  0.007177  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in standardized data\n",
    "data = pd.read_pickle('standardization_data.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Split Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_fromscam = data.pop('from_scam')\n",
    "y_toscam = data.pop('to_scam')\n",
    "x_train,x_test,y_train,y_test = train_test_split(data,y_fromscam) # first predict from scam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desired Metrics and Models\n",
    "## Metrics\n",
    "- Recall\n",
    "- Precision\n",
    "- Accuracy\n",
    "- F1\n",
    "- AUC\n",
    "\n",
    "## Models\n",
    "- Xgboost\n",
    "- Random Forest\n",
    "- L1-Logistic\n",
    "- L2-Logistic\n",
    "- KNN\n",
    "- SVM\n",
    "- Naive Bayes\n",
    "- DNN\n",
    "- Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-18 11:19:23] {2055} INFO - task = classification\n",
      "[flaml.automl: 02-18 11:19:23] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 02-18 11:19:23] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 02-18 11:19:23] {2142} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 02-18 11:19:23] {2200} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf', 'lrl1']\n",
      "[flaml.automl: 02-18 11:19:23] {2453} INFO - iteration 0, current learner xgboost\n",
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[flaml.automl: 02-18 11:19:24] {2569} INFO - Estimated sufficient time budget=18859s. Estimated necessary time budget=193s.\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.5s,\testimator xgboost's best error=0.0269,\tbest estimator xgboost's best error=0.0269\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0269,\tbest estimator xgboost's best error=0.0269\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0269,\tbest estimator xgboost's best error=0.0269\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0269,\tbest estimator xgboost's best error=0.0269\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0266,\tbest estimator xgboost's best error=0.0266\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0266,\tbest estimator xgboost's best error=0.0266\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.0189,\tbest estimator xgboost's best error=0.0189\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.0185,\tbest estimator xgboost's best error=0.0185\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0170,\tbest estimator xgboost's best error=0.0170\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 1.0s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 1.1s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 1.1s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 1.2s,\testimator xgboost's best error=0.0114,\tbest estimator xgboost's best error=0.0114\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:24] {2621} INFO -  at 1.3s,\testimator xgboost's best error=0.0114,\tbest estimator xgboost's best error=0.0114\n",
      "[flaml.automl: 02-18 11:19:24] {2453} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:25] {2621} INFO -  at 1.5s,\testimator xgboost's best error=0.0114,\tbest estimator xgboost's best error=0.0114\n",
      "[flaml.automl: 02-18 11:19:25] {2453} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:25] {2621} INFO -  at 1.6s,\testimator xgboost's best error=0.0114,\tbest estimator xgboost's best error=0.0114\n",
      "[flaml.automl: 02-18 11:19:25] {2453} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:25] {2621} INFO -  at 2.1s,\testimator xgboost's best error=0.0112,\tbest estimator xgboost's best error=0.0112\n",
      "[flaml.automl: 02-18 11:19:25] {2453} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 02-18 11:19:25] {2621} INFO -  at 2.5s,\testimator rf's best error=0.0368,\tbest estimator xgboost's best error=0.0112\n",
      "[flaml.automl: 02-18 11:19:25] {2453} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 02-18 11:19:26] {2621} INFO -  at 2.8s,\testimator rf's best error=0.0279,\tbest estimator xgboost's best error=0.0112\n",
      "[flaml.automl: 02-18 11:19:26] {2453} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:26] {2621} INFO -  at 3.1s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
      "[flaml.automl: 02-18 11:19:26] {2453} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:27] {2621} INFO -  at 3.7s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
      "[flaml.automl: 02-18 11:19:27] {2453} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 02-18 11:19:27] {2621} INFO -  at 4.0s,\testimator rf's best error=0.0279,\tbest estimator xgboost's best error=0.0079\n",
      "[flaml.automl: 02-18 11:19:27] {2453} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 02-18 11:19:27] {2621} INFO -  at 4.5s,\testimator rf's best error=0.0279,\tbest estimator xgboost's best error=0.0079\n",
      "[flaml.automl: 02-18 11:19:27] {2453} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:28] {2621} INFO -  at 4.7s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
      "[flaml.automl: 02-18 11:19:28] {2453} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:28] {2621} INFO -  at 5.2s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:28] {2453} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:28] {2621} INFO -  at 5.3s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:28] {2453} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 02-18 11:19:29] {2621} INFO -  at 5.6s,\testimator rf's best error=0.0267,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:29] {2453} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:30] {2621} INFO -  at 6.6s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:30] {2453} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:30] {2621} INFO -  at 7.0s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:30] {2453} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:30] {2621} INFO -  at 7.4s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:30] {2453} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:31] {2621} INFO -  at 7.5s,\testimator xgboost's best error=0.0077,\tbest estimator xgboost's best error=0.0077\n",
      "[flaml.automl: 02-18 11:19:31] {2453} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:33] {2621} INFO -  at 9.8s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:33] {2453} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:35] {2621} INFO -  at 11.7s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:35] {2453} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:37] {2621} INFO -  at 13.5s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:37] {2453} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:40] {2621} INFO -  at 16.8s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:40] {2453} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:41] {2621} INFO -  at 18.0s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:41] {2453} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:48] {2621} INFO -  at 25.4s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:48] {2453} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 02-18 11:19:49] {2621} INFO -  at 25.9s,\testimator rf's best error=0.0267,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:49] {2453} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:49] {2621} INFO -  at 26.2s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:49] {2453} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:51] {2621} INFO -  at 27.6s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:51] {2453} INFO - iteration 45, current learner rf\n",
      "[flaml.automl: 02-18 11:19:51] {2621} INFO -  at 28.0s,\testimator rf's best error=0.0180,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:51] {2453} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 02-18 11:19:51] {2621} INFO -  at 28.4s,\testimator rf's best error=0.0161,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:51] {2453} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 02-18 11:19:52] {2621} INFO -  at 28.8s,\testimator rf's best error=0.0161,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:52] {2453} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 02-18 11:19:52] {2621} INFO -  at 29.2s,\testimator rf's best error=0.0161,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:52] {2453} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:55] {2621} INFO -  at 31.5s,\testimator xgboost's best error=0.0065,\tbest estimator xgboost's best error=0.0065\n",
      "[flaml.automl: 02-18 11:19:55] {2453} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 02-18 11:19:58] {2621} INFO -  at 34.9s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:19:58] {2453} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:00] {2621} INFO -  at 37.1s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:00] {2453} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:01] {2621} INFO -  at 38.2s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:01] {2453} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 02-18 11:20:02] {2621} INFO -  at 38.7s,\testimator rf's best error=0.0144,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:02] {2453} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:10] {2621} INFO -  at 47.3s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:10] {2453} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:15] {2621} INFO -  at 51.9s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:15] {2453} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 02-18 11:20:15] {2621} INFO -  at 52.4s,\testimator rf's best error=0.0144,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:15] {2453} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:16] {2621} INFO -  at 53.4s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:16] {2453} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 02-18 11:20:17] {2621} INFO -  at 53.9s,\testimator rf's best error=0.0127,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:17] {2453} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:24] {2621} INFO -  at 60.8s,\testimator xgboost's best error=0.0064,\tbest estimator xgboost's best error=0.0064\n",
      "[flaml.automl: 02-18 11:20:27] {2847} INFO - retrain xgboost for 3.6s\n",
      "[flaml.automl: 02-18 11:20:27] {2852} INFO - retrained model: XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.5954954401426565, colsample_bynode=1,\n",
      "              colsample_bytree=0.7092399955989741, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.04035932182843075,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=55,\n",
      "              min_child_weight=0.042589012347266295, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=958, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.7268198241319971,\n",
      "              reg_lambda=0.021715171334551808, scale_pos_weight=1,\n",
      "              subsample=0.9506698364031758, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "[flaml.automl: 02-18 11:20:27] {2229} INFO - fit succeeded\n",
      "[flaml.automl: 02-18 11:20:27] {2231} INFO - Time taken to find the best model: 34.92864990234375\n",
      "[flaml.automl: 02-18 11:20:28] {2055} INFO - task = classification\n",
      "[flaml.automl: 02-18 11:20:28] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 02-18 11:20:28] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 02-18 11:20:28] {2142} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 02-18 11:20:28] {2200} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf', 'lrl1']\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2569} INFO - Estimated sufficient time budget=894s. Estimated necessary time budget=9s.\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.1s,\testimator xgboost's best error=0.2020,\tbest estimator xgboost's best error=0.2020\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.2s,\testimator xgboost's best error=0.2020,\tbest estimator xgboost's best error=0.2020\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.2s,\testimator xgboost's best error=0.1337,\tbest estimator xgboost's best error=0.1337\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 3, current learner rf\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.5s,\testimator rf's best error=0.1265,\tbest estimator rf's best error=0.1265\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0510,\tbest estimator xgboost's best error=0.0510\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0404,\tbest estimator xgboost's best error=0.0404\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.0404,\tbest estimator xgboost's best error=0.0404\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.0272,\tbest estimator xgboost's best error=0.0272\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.0272,\tbest estimator xgboost's best error=0.0272\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0272,\tbest estimator xgboost's best error=0.0272\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0127,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.0127,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.0127,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.0127,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:28] {2621} INFO -  at 1.0s,\testimator xgboost's best error=0.0127,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:28] {2453} INFO - iteration 15, current learner rf\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.3s,\testimator rf's best error=0.0550,\tbest estimator xgboost's best error=0.0127\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.4s,\testimator xgboost's best error=0.0094,\tbest estimator xgboost's best error=0.0094\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 17, current learner rf\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.7s,\testimator rf's best error=0.0550,\tbest estimator xgboost's best error=0.0094\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.8s,\testimator xgboost's best error=0.0094,\tbest estimator xgboost's best error=0.0094\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.9s,\testimator xgboost's best error=0.0094,\tbest estimator xgboost's best error=0.0094\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 1.9s,\testimator xgboost's best error=0.0094,\tbest estimator xgboost's best error=0.0094\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:29] {2621} INFO -  at 2.1s,\testimator xgboost's best error=0.0063,\tbest estimator xgboost's best error=0.0063\n",
      "[flaml.automl: 02-18 11:20:29] {2453} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 02-18 11:20:30] {2621} INFO -  at 2.5s,\testimator rf's best error=0.0550,\tbest estimator xgboost's best error=0.0063\n",
      "[flaml.automl: 02-18 11:20:30] {2453} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 02-18 11:20:30] {2621} INFO -  at 2.8s,\testimator rf's best error=0.0492,\tbest estimator xgboost's best error=0.0063\n",
      "[flaml.automl: 02-18 11:20:30] {2453} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:30] {2621} INFO -  at 2.9s,\testimator xgboost's best error=0.0063,\tbest estimator xgboost's best error=0.0063\n",
      "[flaml.automl: 02-18 11:20:30] {2453} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:31] {2621} INFO -  at 3.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:31] {2453} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:31] {2621} INFO -  at 3.9s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:31] {2453} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:32] {2621} INFO -  at 4.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:32] {2453} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:32] {2621} INFO -  at 4.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:32] {2453} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:33] {2621} INFO -  at 5.2s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:33] {2453} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:33] {2621} INFO -  at 5.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:33] {2453} INFO - iteration 31, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:20:33] {2621} INFO -  at 5.8s,\testimator lrl1's best error=0.4763,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:33] {2453} INFO - iteration 32, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:20:33] {2621} INFO -  at 6.0s,\testimator lrl1's best error=0.4763,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:33] {2453} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:34] {2621} INFO -  at 7.0s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:34] {2453} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:35] {2621} INFO -  at 7.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:35] {2453} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 02-18 11:20:35] {2621} INFO -  at 7.9s,\testimator rf's best error=0.0439,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:35] {2453} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:36] {2621} INFO -  at 8.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:36] {2453} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 02-18 11:20:36] {2621} INFO -  at 8.6s,\testimator rf's best error=0.0367,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:36] {2453} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:36] {2621} INFO -  at 8.8s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:36] {2453} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 02-18 11:20:37] {2621} INFO -  at 9.2s,\testimator rf's best error=0.0248,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:37] {2453} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 02-18 11:20:37] {2621} INFO -  at 9.6s,\testimator rf's best error=0.0248,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:37] {2453} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:39] {2621} INFO -  at 11.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:39] {2453} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 02-18 11:20:39] {2621} INFO -  at 11.8s,\testimator rf's best error=0.0248,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:39] {2453} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 02-18 11:20:40] {2621} INFO -  at 12.2s,\testimator rf's best error=0.0183,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:40] {2453} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 02-18 11:20:40] {2621} INFO -  at 12.7s,\testimator rf's best error=0.0183,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:40] {2453} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:40] {2621} INFO -  at 13.0s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:40] {2453} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 02-18 11:20:41] {2621} INFO -  at 13.5s,\testimator rf's best error=0.0183,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:41] {2453} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:41] {2621} INFO -  at 13.9s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:41] {2453} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:42] {2621} INFO -  at 14.4s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:42] {2453} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 02-18 11:20:42] {2621} INFO -  at 14.7s,\testimator rf's best error=0.0183,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:42] {2453} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:43] {2621} INFO -  at 15.2s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:43] {2453} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:44] {2621} INFO -  at 16.7s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:44] {2453} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:44] {2621} INFO -  at 16.8s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:44] {2453} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:45] {2621} INFO -  at 17.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:45] {2453} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 02-18 11:20:45] {2621} INFO -  at 17.7s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:45] {2453} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:46] {2621} INFO -  at 18.2s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:46] {2453} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:47] {2621} INFO -  at 19.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:47] {2453} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:47] {2621} INFO -  at 19.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:47] {2453} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:47] {2621} INFO -  at 19.7s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:47] {2453} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 02-18 11:20:48] {2621} INFO -  at 20.1s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:48] {2453} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:49] {2621} INFO -  at 21.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:49] {2453} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 02-18 11:20:49] {2621} INFO -  at 21.8s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:49] {2453} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 02-18 11:20:50] {2621} INFO -  at 22.2s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:50] {2453} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:50] {2621} INFO -  at 22.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:50] {2453} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:50] {2621} INFO -  at 22.9s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:50] {2453} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 02-18 11:20:51] {2621} INFO -  at 23.4s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:51] {2453} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:51] {2621} INFO -  at 23.8s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:51] {2453} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:52] {2621} INFO -  at 24.1s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:52] {2453} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:52] {2621} INFO -  at 24.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:52] {2453} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 02-18 11:20:52] {2621} INFO -  at 24.8s,\testimator rf's best error=0.0152,\tbest estimator xgboost's best error=0.0044\n",
      "[flaml.automl: 02-18 11:20:52] {2453} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 02-18 11:20:53] {2621} INFO -  at 25.4s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:53] {2453} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 02-18 11:20:53] {2621} INFO -  at 25.9s,\testimator rf's best error=0.0114,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:53] {2453} INFO - iteration 72, current learner rf\n",
      "[flaml.automl: 02-18 11:20:54] {2621} INFO -  at 26.5s,\testimator rf's best error=0.0114,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:54] {2453} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 02-18 11:20:54] {2621} INFO -  at 26.9s,\testimator rf's best error=0.0065,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:54] {2453} INFO - iteration 74, current learner rf\n",
      "[flaml.automl: 02-18 11:20:55] {2621} INFO -  at 27.5s,\testimator rf's best error=0.0065,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:55] {2453} INFO - iteration 75, current learner rf\n",
      "[flaml.automl: 02-18 11:20:55] {2621} INFO -  at 27.9s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:55] {2453} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 02-18 11:20:56] {2621} INFO -  at 28.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:56] {2453} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 02-18 11:20:56] {2621} INFO -  at 28.8s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:56] {2453} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 02-18 11:20:57] {2621} INFO -  at 29.3s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:57] {2453} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 02-18 11:20:57] {2621} INFO -  at 29.7s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:57] {2453} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 02-18 11:20:58] {2621} INFO -  at 30.2s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:58] {2453} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 02-18 11:20:58] {2621} INFO -  at 30.7s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:58] {2453} INFO - iteration 82, current learner rf\n",
      "[flaml.automl: 02-18 11:20:59] {2621} INFO -  at 31.1s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:59] {2453} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 02-18 11:20:59] {2621} INFO -  at 31.6s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:59] {2453} INFO - iteration 84, current learner rf\n",
      "[flaml.automl: 02-18 11:20:59] {2621} INFO -  at 32.0s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:20:59] {2453} INFO - iteration 85, current learner rf\n",
      "[flaml.automl: 02-18 11:21:00] {2621} INFO -  at 32.5s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:00] {2453} INFO - iteration 86, current learner rf\n",
      "[flaml.automl: 02-18 11:21:00] {2621} INFO -  at 33.0s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:00] {2453} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:01] {2621} INFO -  at 34.0s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:01] {2453} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 02-18 11:21:02] {2621} INFO -  at 34.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:02] {2453} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 02-18 11:21:02] {2621} INFO -  at 34.8s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:02] {2453} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 02-18 11:21:03] {2621} INFO -  at 35.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:03] {2453} INFO - iteration 91, current learner rf\n",
      "[flaml.automl: 02-18 11:21:03] {2621} INFO -  at 36.0s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:03] {2453} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 02-18 11:21:04] {2621} INFO -  at 36.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:04] {2453} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:05] {2621} INFO -  at 37.2s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:05] {2453} INFO - iteration 94, current learner rf\n",
      "[flaml.automl: 02-18 11:21:05] {2621} INFO -  at 37.6s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:05] {2453} INFO - iteration 95, current learner rf\n",
      "[flaml.automl: 02-18 11:21:06] {2621} INFO -  at 38.1s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:06] {2453} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 02-18 11:21:06] {2621} INFO -  at 38.5s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:06] {2453} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:07] {2621} INFO -  at 39.9s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:07] {2453} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:08] {2621} INFO -  at 40.2s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:08] {2453} INFO - iteration 99, current learner rf\n",
      "[flaml.automl: 02-18 11:21:08] {2621} INFO -  at 40.6s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:08] {2453} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 02-18 11:21:08] {2621} INFO -  at 41.1s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:08] {2453} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:09] {2621} INFO -  at 42.0s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:09] {2453} INFO - iteration 102, current learner rf\n",
      "[flaml.automl: 02-18 11:21:10] {2621} INFO -  at 42.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:10] {2453} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:10] {2621} INFO -  at 43.0s,\testimator xgboost's best error=0.0041,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:10] {2453} INFO - iteration 104, current learner rf\n",
      "[flaml.automl: 02-18 11:21:11] {2621} INFO -  at 43.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:11] {2453} INFO - iteration 105, current learner rf\n",
      "[flaml.automl: 02-18 11:21:11] {2621} INFO -  at 43.9s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0041\n",
      "[flaml.automl: 02-18 11:21:11] {2453} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:12] {2621} INFO -  at 44.5s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:12] {2453} INFO - iteration 107, current learner rf\n",
      "[flaml.automl: 02-18 11:21:12] {2621} INFO -  at 44.9s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:12] {2453} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:13] {2621} INFO -  at 45.6s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:13] {2453} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:15] {2621} INFO -  at 48.0s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:15] {2453} INFO - iteration 110, current learner rf\n",
      "[flaml.automl: 02-18 11:21:16] {2621} INFO -  at 48.4s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:16] {2453} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:16] {2621} INFO -  at 48.7s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:16] {2453} INFO - iteration 112, current learner rf\n",
      "[flaml.automl: 02-18 11:21:17] {2621} INFO -  at 49.2s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:17] {2453} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:17] {2621} INFO -  at 49.6s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:17] {2453} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:18] {2621} INFO -  at 50.7s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:18] {2453} INFO - iteration 115, current learner rf\n",
      "[flaml.automl: 02-18 11:21:19] {2621} INFO -  at 51.1s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:19] {2453} INFO - iteration 116, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:20] {2621} INFO -  at 52.7s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:20] {2453} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:21] {2621} INFO -  at 53.2s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:21] {2453} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:22] {2621} INFO -  at 54.1s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:22] {2453} INFO - iteration 119, current learner rf\n",
      "[flaml.automl: 02-18 11:21:22] {2621} INFO -  at 54.6s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:22] {2453} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 02-18 11:21:22] {2621} INFO -  at 55.0s,\testimator rf's best error=0.0050,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:22] {2453} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:23] {2621} INFO -  at 55.6s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:23] {2453} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:23] {2621} INFO -  at 55.7s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:23] {2453} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:27] {2621} INFO -  at 59.2s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:27] {2453} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:28] {2621} INFO -  at 60.1s,\testimator xgboost's best error=0.0037,\tbest estimator xgboost's best error=0.0037\n",
      "[flaml.automl: 02-18 11:21:28] {2847} INFO - retrain xgboost for 0.6s\n",
      "[flaml.automl: 02-18 11:21:28] {2852} INFO - retrained model: XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.710294071511803, colsample_bynode=1,\n",
      "              colsample_bytree=0.9671752376505114, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.09910874221608323,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=70,\n",
      "              min_child_weight=0.1821358019579942, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=169, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.01613253208796762, reg_lambda=0.029367721981303656,\n",
      "              scale_pos_weight=1, subsample=1.0, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "[flaml.automl: 02-18 11:21:28] {2229} INFO - fit succeeded\n",
      "[flaml.automl: 02-18 11:21:28] {2231} INFO - Time taken to find the best model: 44.48514461517334\n",
      "[flaml.automl: 02-18 11:21:28] {2245} WARNING - Time taken to find the best model is 74% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl: 02-18 11:21:28] {2055} INFO - task = classification\n",
      "[flaml.automl: 02-18 11:21:28] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 02-18 11:21:28] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 02-18 11:21:28] {2142} INFO - Minimizing error metric: 1-f1\n",
      "[flaml.automl: 02-18 11:21:28] {2200} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf', 'lrl1']\n",
      "[flaml.automl: 02-18 11:21:28] {2453} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:28] {2569} INFO - Estimated sufficient time budget=1063s. Estimated necessary time budget=11s.\n",
      "[flaml.automl: 02-18 11:21:28] {2621} INFO -  at 0.2s,\testimator xgboost's best error=0.5414,\tbest estimator xgboost's best error=0.5414\n",
      "[flaml.automl: 02-18 11:21:28] {2453} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:28] {2621} INFO -  at 0.2s,\testimator xgboost's best error=0.5414,\tbest estimator xgboost's best error=0.5414\n",
      "[flaml.automl: 02-18 11:21:28] {2453} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:28] {2621} INFO -  at 0.2s,\testimator xgboost's best error=0.5414,\tbest estimator xgboost's best error=0.5414\n",
      "[flaml.automl: 02-18 11:21:28] {2453} INFO - iteration 3, current learner rf\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.5s,\testimator rf's best error=0.6695,\tbest estimator xgboost's best error=0.5414\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.5414,\tbest estimator xgboost's best error=0.5414\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.5338,\tbest estimator xgboost's best error=0.5338\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.6s,\testimator xgboost's best error=0.5338,\tbest estimator xgboost's best error=0.5338\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.3108,\tbest estimator xgboost's best error=0.3108\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.7s,\testimator xgboost's best error=0.3103,\tbest estimator xgboost's best error=0.3103\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.8s,\testimator xgboost's best error=0.2783,\tbest estimator xgboost's best error=0.2783\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 0.9s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 1.0s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 1.1s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:29] {2621} INFO -  at 1.2s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:29] {2453} INFO - iteration 15, current learner rf\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 1.5s,\testimator rf's best error=0.4887,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 1.6s,\testimator xgboost's best error=0.2407,\tbest estimator xgboost's best error=0.2407\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 1.7s,\testimator xgboost's best error=0.2344,\tbest estimator xgboost's best error=0.2344\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 1.8s,\testimator xgboost's best error=0.2344,\tbest estimator xgboost's best error=0.2344\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 1.9s,\testimator xgboost's best error=0.1758,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 2.0s,\testimator xgboost's best error=0.1758,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:30] {2621} INFO -  at 2.3s,\testimator xgboost's best error=0.1758,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:30] {2453} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 02-18 11:21:31] {2621} INFO -  at 2.6s,\testimator rf's best error=0.4887,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:31] {2453} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 02-18 11:21:31] {2621} INFO -  at 3.1s,\testimator rf's best error=0.4887,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:31] {2453} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:31] {2621} INFO -  at 3.2s,\testimator xgboost's best error=0.1758,\tbest estimator xgboost's best error=0.1758\n",
      "[flaml.automl: 02-18 11:21:31] {2453} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:32] {2621} INFO -  at 3.7s,\testimator xgboost's best error=0.1744,\tbest estimator xgboost's best error=0.1744\n",
      "[flaml.automl: 02-18 11:21:32] {2453} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 02-18 11:21:32] {2621} INFO -  at 4.1s,\testimator rf's best error=0.3630,\tbest estimator xgboost's best error=0.1744\n",
      "[flaml.automl: 02-18 11:21:32] {2453} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 02-18 11:21:33] {2621} INFO -  at 4.5s,\testimator rf's best error=0.3630,\tbest estimator xgboost's best error=0.1744\n",
      "[flaml.automl: 02-18 11:21:33] {2453} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:33] {2621} INFO -  at 4.9s,\testimator xgboost's best error=0.1154,\tbest estimator xgboost's best error=0.1154\n",
      "[flaml.automl: 02-18 11:21:33] {2453} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:34] {2621} INFO -  at 5.5s,\testimator xgboost's best error=0.1154,\tbest estimator xgboost's best error=0.1154\n",
      "[flaml.automl: 02-18 11:21:34] {2453} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:34] {2621} INFO -  at 5.8s,\testimator xgboost's best error=0.1154,\tbest estimator xgboost's best error=0.1154\n",
      "[flaml.automl: 02-18 11:21:34] {2453} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 02-18 11:21:34] {2621} INFO -  at 6.1s,\testimator rf's best error=0.3630,\tbest estimator xgboost's best error=0.1154\n",
      "[flaml.automl: 02-18 11:21:34] {2453} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:35] {2621} INFO -  at 6.7s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:35] {2453} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:35] {2621} INFO -  at 6.9s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:35] {2453} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 02-18 11:21:35] {2621} INFO -  at 7.3s,\testimator rf's best error=0.2762,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:35] {2453} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:37] {2621} INFO -  at 8.3s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:37] {2453} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:37] {2621} INFO -  at 8.7s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:37] {2453} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:37] {2621} INFO -  at 9.2s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:37] {2453} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:38] {2621} INFO -  at 9.4s,\testimator xgboost's best error=0.1111,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:38] {2453} INFO - iteration 39, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:38] {2621} INFO -  at 9.7s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:38] {2453} INFO - iteration 40, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:38] {2621} INFO -  at 9.9s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.1111\n",
      "[flaml.automl: 02-18 11:21:38] {2453} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:41] {2621} INFO -  at 12.4s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:41] {2453} INFO - iteration 42, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:41] {2621} INFO -  at 12.8s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:41] {2453} INFO - iteration 43, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:42] {2621} INFO -  at 13.8s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:42] {2453} INFO - iteration 44, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:43] {2621} INFO -  at 14.8s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:43] {2453} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:45] {2621} INFO -  at 17.1s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:45] {2453} INFO - iteration 46, current learner lrl1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "[flaml.automl: 02-18 11:21:46] {2621} INFO -  at 18.0s,\testimator lrl1's best error=0.8830,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:46] {2453} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:48] {2621} INFO -  at 19.8s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:48] {2453} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 02-18 11:21:48] {2621} INFO -  at 20.2s,\testimator rf's best error=0.2762,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:48] {2453} INFO - iteration 49, current learner lrl1\n",
      "[flaml.automl: 02-18 11:21:48] {2647} INFO - stop trying learner lrl1\n",
      "[flaml.automl: 02-18 11:21:48] {2453} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:52] {2621} INFO -  at 23.5s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:52] {2453} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 02-18 11:21:53] {2621} INFO -  at 24.7s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:21:53] {2453} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:00] {2621} INFO -  at 32.0s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:00] {2453} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:01] {2621} INFO -  at 32.5s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:01] {2453} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 02-18 11:22:01] {2621} INFO -  at 32.9s,\testimator rf's best error=0.2762,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:01] {2453} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:03] {2621} INFO -  at 34.3s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:03] {2453} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:05] {2621} INFO -  at 36.8s,\testimator xgboost's best error=0.0954,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:05] {2453} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 02-18 11:22:05] {2621} INFO -  at 37.3s,\testimator rf's best error=0.2252,\tbest estimator xgboost's best error=0.0954\n",
      "[flaml.automl: 02-18 11:22:05] {2453} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:09] {2621} INFO -  at 41.0s,\testimator xgboost's best error=0.0924,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:09] {2453} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 02-18 11:22:10] {2621} INFO -  at 41.4s,\testimator rf's best error=0.2252,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:10] {2453} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:12] {2621} INFO -  at 43.4s,\testimator xgboost's best error=0.0924,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:12] {2453} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 02-18 11:22:12] {2621} INFO -  at 43.8s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:12] {2453} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 02-18 11:22:12] {2621} INFO -  at 44.3s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:12] {2453} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:14] {2621} INFO -  at 45.4s,\testimator xgboost's best error=0.0924,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:14] {2453} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:22] {2621} INFO -  at 53.8s,\testimator xgboost's best error=0.0924,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:22] {2453} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl: 02-18 11:22:27] {2621} INFO -  at 58.4s,\testimator xgboost's best error=0.0924,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:27] {2453} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 02-18 11:22:27] {2621} INFO -  at 58.7s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:27] {2453} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 02-18 11:22:27] {2621} INFO -  at 59.1s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:27] {2453} INFO - iteration 68, current learner rf\n",
      "[flaml.automl: 02-18 11:22:27] {2621} INFO -  at 59.2s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:27] {2453} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 02-18 11:22:27] {2621} INFO -  at 59.3s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:27] {2453} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 02-18 11:22:28] {2621} INFO -  at 59.4s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:28] {2453} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 02-18 11:22:28] {2621} INFO -  at 59.5s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:28] {2453} INFO - iteration 72, current learner rf\n",
      "[flaml.automl: 02-18 11:22:28] {2621} INFO -  at 59.6s,\testimator rf's best error=0.2202,\tbest estimator xgboost's best error=0.0924\n",
      "[flaml.automl: 02-18 11:22:32] {2847} INFO - retrain xgboost for 3.9s\n",
      "[flaml.automl: 02-18 11:22:32] {2852} INFO - retrained model: XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.5954954401426565, colsample_bynode=1,\n",
      "              colsample_bytree=0.7092399955989741, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.04035932182843075,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=55,\n",
      "              min_child_weight=0.042589012347266295, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=958, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.7268198241319971,\n",
      "              reg_lambda=0.021715171334551808, scale_pos_weight=1,\n",
      "              subsample=0.9506698364031758, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "[flaml.automl: 02-18 11:22:32] {2229} INFO - fit succeeded\n",
      "[flaml.automl: 02-18 11:22:32] {2231} INFO - Time taken to find the best model: 40.9740149974823\n"
     ]
    }
   ],
   "source": [
    "# for each metric of interst run automl binary classification for first 3 models\n",
    "results =[]\n",
    "for i in ['accuracy','roc_auc','f1']:\n",
    "    automl = AutoML()\n",
    "    automl_settings = {\n",
    "        \"metric\":i,\n",
    "        'task':'classification',\n",
    "        'log_file_name':i,\n",
    "    }\n",
    "    \n",
    "    automl.fit(X_train=x_train, y_train=y_train,\n",
    "           **automl_settings,estimator_list=['xgboost','rf','lrl1'])\n",
    "    \n",
    "    results.append(automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "import pickle\n",
    "with open('standrdization_results_0_3.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('standrdization_results_0_3.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-18 11:25:39] {2055} INFO - task = classification\n",
      "[flaml.automl: 02-18 11:25:39] {2057} INFO - Data split method: stratified\n",
      "[flaml.automl: 02-18 11:25:39] {2061} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 02-18 11:25:39] {2142} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 02-18 11:25:39] {2200} INFO - List of ML learners in AutoML Run: ['extra_tree', 'lgbm', 'lrl2', 'kneighbor']\n",
      "[flaml.automl: 02-18 11:25:39] {2453} INFO - iteration 0, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:40] {2569} INFO - Estimated sufficient time budget=15574s. Estimated necessary time budget=47s.\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.5s,\testimator extra_tree's best error=0.0368,\tbest estimator extra_tree's best error=0.0368\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.5s,\testimator lgbm's best error=0.0368,\tbest estimator extra_tree's best error=0.0368\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.5s,\testimator lgbm's best error=0.0368,\tbest estimator extra_tree's best error=0.0368\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.5s,\testimator lgbm's best error=0.0288,\tbest estimator lgbm's best error=0.0288\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.9s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0288\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.9s,\testimator lgbm's best error=0.0288,\tbest estimator lgbm's best error=0.0288\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:40] {2621} INFO -  at 0.9s,\testimator lgbm's best error=0.0288,\tbest estimator lgbm's best error=0.0288\n",
      "[flaml.automl: 02-18 11:25:40] {2453} INFO - iteration 7, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.2s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0288\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.0183,\tbest estimator lgbm's best error=0.0183\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.0183,\tbest estimator lgbm's best error=0.0183\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.0170,\tbest estimator lgbm's best error=0.0170\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.0148,\tbest estimator lgbm's best error=0.0148\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.3s,\testimator lgbm's best error=0.0148,\tbest estimator lgbm's best error=0.0148\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.4s,\testimator lgbm's best error=0.0103,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.5s,\testimator lgbm's best error=0.0103,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.5s,\testimator lgbm's best error=0.0103,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 1.9s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 2.0s,\testimator lgbm's best error=0.0103,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 2.1s,\testimator lgbm's best error=0.0103,\tbest estimator lgbm's best error=0.0103\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:41] {2621} INFO -  at 2.2s,\testimator lgbm's best error=0.0097,\tbest estimator lgbm's best error=0.0097\n",
      "[flaml.automl: 02-18 11:25:41] {2453} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:42] {2621} INFO -  at 2.5s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0097\n",
      "[flaml.automl: 02-18 11:25:42] {2453} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:42] {2621} INFO -  at 2.7s,\testimator lgbm's best error=0.0097,\tbest estimator lgbm's best error=0.0097\n",
      "[flaml.automl: 02-18 11:25:42] {2453} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:42] {2621} INFO -  at 2.8s,\testimator lgbm's best error=0.0097,\tbest estimator lgbm's best error=0.0097\n",
      "[flaml.automl: 02-18 11:25:42] {2453} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:42] {2621} INFO -  at 3.0s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
      "[flaml.automl: 02-18 11:25:42] {2453} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:42] {2621} INFO -  at 3.1s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
      "[flaml.automl: 02-18 11:25:42] {2453} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:43] {2621} INFO -  at 3.3s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
      "[flaml.automl: 02-18 11:25:43] {2453} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:43] {2621} INFO -  at 3.9s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
      "[flaml.automl: 02-18 11:25:43] {2453} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:43] {2621} INFO -  at 4.1s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:43] {2453} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:44] {2621} INFO -  at 4.4s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:44] {2453} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:44] {2621} INFO -  at 4.8s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:44] {2453} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:44] {2621} INFO -  at 5.2s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:44] {2453} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:45] {2621} INFO -  at 5.3s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:45] {2453} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:45] {2621} INFO -  at 5.7s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:45] {2453} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:45] {2621} INFO -  at 5.9s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:45] {2453} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:45] {2621} INFO -  at 6.2s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:45] {2453} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:46] {2621} INFO -  at 6.6s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:46] {2453} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:46] {2621} INFO -  at 6.7s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:46] {2453} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:46] {2621} INFO -  at 7.2s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:46] {2453} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:47] {2621} INFO -  at 7.2s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:47] {2453} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:47] {2621} INFO -  at 7.3s,\testimator lgbm's best error=0.0075,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:47] {2453} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:47] {2621} INFO -  at 7.6s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0075\n",
      "[flaml.automl: 02-18 11:25:47] {2453} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:48] {2621} INFO -  at 8.2s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:48] {2453} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:48] {2621} INFO -  at 8.6s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:48] {2453} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:49] {2621} INFO -  at 9.5s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:49] {2453} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:49] {2621} INFO -  at 9.9s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:49] {2453} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:50] {2621} INFO -  at 10.5s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:50] {2453} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 02-18 11:25:50] {2621} INFO -  at 10.9s,\testimator extra_tree's best error=0.0368,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:50] {2453} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 02-18 11:25:53] {2621} INFO -  at 13.9s,\testimator lgbm's best error=0.0064,\tbest estimator lgbm's best error=0.0064\n",
      "[flaml.automl: 02-18 11:25:53] {2453} INFO - iteration 48, current learner lrl2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "current limit exceeds maximum limit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8c3e6b91c2ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     automl1.fit(X_train=x_train, y_train=y_train,\n\u001b[0;32m---> 11\u001b[0;31m            **automl_settings,estimator_list=['extra_tree','lgbm','lrl2','kneighbor'])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2222\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtraining_log_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2721\u001b[0m             )\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_ray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_search_sequential\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2544\u001b[0m                 \u001b[0mtime_budget_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbudget_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_time_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m                 \u001b[0muse_ray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m             )\n\u001b[1;32m   2548\u001b[0m             \u001b[0mtime_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_run_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_incumbent_result_in_evaluation)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"trial {num_trials} config: {trial_to_run.config}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_to_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_compute_with_config_base\u001b[0;34m(config_w_resource, state, estimator)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_training_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrain_final\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/ml.py\u001b[0m in \u001b[0;36mcompute_estimator\u001b[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mlog_training_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_training_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         )\n\u001b[1;32m    580\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/ml.py\u001b[0m in \u001b[0;36mget_val_loss\u001b[0;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, obj, labels, budget, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m#     fit_kwargs['X_val'] = X_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;31m#     fit_kwargs['y_val'] = y_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     val_loss, metric_for_logging, pred_time, _ = _eval_estimator(\n\u001b[1;32m    402\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, budget, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                     \u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                 ):\n\u001b[1;32m    185\u001b[0m                     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/flaml/model.py\u001b[0m in \u001b[0;36mlimit_resource\u001b[0;34m(memory_limit, time_limit)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msoft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLIMIT_AS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msoft\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhard\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmemory_limit\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmemory_limit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetrlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLIMIT_AS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmemory_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mmain_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: current limit exceeds maximum limit"
     ]
    }
   ],
   "source": [
    "# for each metric of interst run automl binary classification for last 3 models\n",
    "for i in ['accuracy','roc_auc','f1']:\n",
    "    automl1 = AutoML()\n",
    "    automl_settings = {\n",
    "        \"metric\":i,\n",
    "        'task':'classification',\n",
    "        'log_file_name':i,\n",
    "    }\n",
    "    \n",
    "    automl1.fit(X_train=x_train, y_train=y_train,\n",
    "           **automl_settings,estimator_list=['lgbm','lrl2','kneighbor'])\n",
    "    \n",
    "    results.append(automl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.974982860880507, colsample_bynode=1,\n",
      "              colsample_bytree=0.6370684336276642, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.02896596391154565,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=251,\n",
      "              min_child_weight=3.4544988117157507, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=515, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,\n",
      "              reg_lambda=0.008415949612508924, scale_pos_weight=1,\n",
      "              subsample=0.9391146021612687, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "\n",
      "Best Configuration: \n",
      "\n",
      "{'n_estimators': 515, 'max_leaves': 251, 'min_child_weight': 3.4544988117157507, 'learning_rate': 0.02896596391154565, 'subsample': 0.9391146021612687, 'colsample_bylevel': 0.974982860880507, 'colsample_bytree': 0.6370684336276642, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.008415949612508924, 'FLAML_sample_size': 48093}\n",
      "Best configuration train time: \n",
      "\n",
      "3.101717948913574\n",
      "\n",
      "Best Iteration\n",
      "56\n",
      "\n",
      "Best loss\n",
      "0.009539842873176219\n",
      "\n",
      "32.76184391975403\n",
      "{0: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}, 0.1635279655456543), 2: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954, 'FLAML_sample_size': 10000}, 0.2098398208618164), 4: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414, 'FLAML_sample_size': 10000}, 0.5630319118499756), 5: ('xgboost', {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968, 'FLAML_sample_size': 10000}, 0.5948259830474854), 9: ('xgboost', {'n_estimators': 4, 'max_leaves': 11, 'min_child_weight': 0.12867253371369008, 'learning_rate': 0.10038798911197372, 'subsample': 0.834639099449601, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.04050321527420467, 'FLAML_sample_size': 10000}, 0.713188886642456), 13: ('xgboost', {'n_estimators': 8, 'max_leaves': 15, 'min_child_weight': 0.659013874348359, 'learning_rate': 0.06438431645166642, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9013070887791416, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.014019146847709309, 'FLAML_sample_size': 10000}, 0.8184237480163574), 21: ('xgboost', {'n_estimators': 17, 'max_leaves': 34, 'min_child_weight': 0.482537191605333, 'learning_rate': 0.020075242698195904, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.847756342161632, 'colsample_bytree': 0.8668431975640492, 'reg_alpha': 0.0015245843735931766, 'reg_lambda': 0.005678542389478797, 'FLAML_sample_size': 48093}, 1.449082851409912), 25: ('xgboost', {'n_estimators': 39, 'max_leaves': 241, 'min_child_weight': 0.3302279645372819, 'learning_rate': 0.011643919178371173, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.7310705843442475, 'colsample_bytree': 0.8092314042000436, 'reg_alpha': 0.001058358871316641, 'reg_lambda': 0.017242830194420036, 'FLAML_sample_size': 48093}, 2.6741838455200195), 26: ('xgboost', {'n_estimators': 36, 'max_leaves': 110, 'min_child_weight': 0.23981803947610958, 'learning_rate': 0.030800305394891078, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.7585765039287123, 'colsample_bytree': 0.758561906106536, 'reg_alpha': 0.015149985296569971, 'reg_lambda': 0.002269520008716221, 'FLAML_sample_size': 48093}, 2.891723871231079), 28: ('xgboost', {'n_estimators': 12, 'max_leaves': 326, 'min_child_weight': 0.07780000636567723, 'learning_rate': 0.015262199787325873, 'subsample': 0.9136143018517056, 'colsample_bylevel': 0.8530724530567352, 'colsample_bytree': 0.8447529507874729, 'reg_alpha': 0.003334251692215521, 'reg_lambda': 0.008596896664041741, 'FLAML_sample_size': 48093}, 3.464589834213257), 31: ('xgboost', {'n_estimators': 47, 'max_leaves': 918, 'min_child_weight': 0.33765554764004047, 'learning_rate': 0.011483965859261468, 'subsample': 0.9533080316554092, 'colsample_bylevel': 0.971065208094155, 'colsample_bytree': 0.8408487788028015, 'reg_alpha': 0.019705105646477896, 'reg_lambda': 0.02065175823552645, 'FLAML_sample_size': 48093}, 4.811968088150024), 52: ('xgboost', {'n_estimators': 301, 'max_leaves': 970, 'min_child_weight': 0.49209682840653773, 'learning_rate': 0.025279598504163062, 'subsample': 0.8903767207568232, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7313321530832727, 'reg_alpha': 0.006777737401075764, 'reg_lambda': 0.016790403430294223, 'FLAML_sample_size': 48093}, 24.73055386543274), 56: ('xgboost', {'n_estimators': 515, 'max_leaves': 251, 'min_child_weight': 3.4544988117157507, 'learning_rate': 0.02896596391154565, 'subsample': 0.9391146021612687, 'colsample_bylevel': 0.974982860880507, 'colsample_bytree': 0.6370684336276642, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.008415949612508924, 'FLAML_sample_size': 48093}, 32.76184391975403)}\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\n",
      "Best Estimator: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.5065217282369652, colsample_bynode=1,\n",
      "              colsample_bytree=0.6351612186749191, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.030323088364337326,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=89,\n",
      "              min_child_weight=0.07082166556325489, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=616, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.10398133070477651, reg_lambda=0.08782946721485667,\n",
      "              scale_pos_weight=1, subsample=0.8144438946633229,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0)\n",
      "\n",
      "Best Configuration: \n",
      "\n",
      "{'n_estimators': 616, 'max_leaves': 89, 'min_child_weight': 0.07082166556325489, 'learning_rate': 0.030323088364337326, 'subsample': 0.8144438946633229, 'colsample_bylevel': 0.5065217282369652, 'colsample_bytree': 0.6351612186749191, 'reg_alpha': 0.10398133070477651, 'reg_lambda': 0.08782946721485667, 'FLAML_sample_size': 48093}\n",
      "Best configuration train time: \n",
      "\n",
      "3.0071399211883545\n",
      "\n",
      "Best Iteration\n",
      "68\n",
      "\n",
      "Best loss\n",
      "0.002656300615484275\n",
      "\n",
      "52.399320125579834\n",
      "{0: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}, 0.14867711067199707), 2: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954, 'FLAML_sample_size': 10000}, 0.19979619979858398), 4: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414, 'FLAML_sample_size': 10000}, 0.5587420463562012), 5: ('xgboost', {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968, 'FLAML_sample_size': 10000}, 0.5922632217407227), 7: ('xgboost', {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 0.8312826637613695, 'learning_rate': 0.4858745329314128, 'subsample': 0.9647550813352507, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931898, 'FLAML_sample_size': 10000}, 0.6652870178222656), 8: ('xgboost', {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 1.6931625792034866, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0016804960453779686, 'reg_lambda': 0.35417434690207034, 'FLAML_sample_size': 10000}, 0.7235569953918457), 16: ('xgboost', {'n_estimators': 45, 'max_leaves': 8, 'min_child_weight': 8.671762333563443, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.9251297694154026, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.12258834626578076, 'FLAML_sample_size': 48093}, 1.8697829246520996), 24: ('xgboost', {'n_estimators': 97, 'max_leaves': 18, 'min_child_weight': 6.349559554939941, 'learning_rate': 0.19997653978110663, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.7728861115770347, 'colsample_bytree': 0.7167459701136535, 'reg_alpha': 0.0015245843735931766, 'reg_lambda': 0.049655170053382026, 'FLAML_sample_size': 48093}, 3.483211040496826), 28: ('xgboost', {'n_estimators': 220, 'max_leaves': 128, 'min_child_weight': 4.34536894567712, 'learning_rate': 0.11598916644682901, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.6562003537596502, 'colsample_bytree': 0.6591341767496479, 'reg_alpha': 0.001058358871316641, 'reg_lambda': 0.1507773662290303, 'FLAML_sample_size': 48093}, 5.335188865661621), 56: ('xgboost', {'n_estimators': 129, 'max_leaves': 495, 'min_child_weight': 0.6190021745475484, 'learning_rate': 0.10122775708629668, 'subsample': 0.7925669483597021, 'colsample_bylevel': 0.6812174928791432, 'colsample_bytree': 0.7533978962052564, 'reg_alpha': 0.00787287956535374, 'reg_lambda': 0.3008113075415533, 'FLAML_sample_size': 48093}, 31.050148010253906), 58: ('xgboost', {'n_estimators': 183, 'max_leaves': 518, 'min_child_weight': 0.09633030270457457, 'learning_rate': 0.028084166983832867, 'subsample': 0.825306995670431, 'colsample_bylevel': 0.5421033509522943, 'colsample_bytree': 0.6742025516212758, 'reg_alpha': 0.010703182705824125, 'reg_lambda': 0.18365572197357422, 'FLAML_sample_size': 48093}, 34.718398094177246), 60: ('xgboost', {'n_estimators': 85, 'max_leaves': 217, 'min_child_weight': 0.1009597538132914, 'learning_rate': 0.08314694958293746, 'subsample': 0.6622564400274157, 'colsample_bylevel': 0.5161483828725835, 'colsample_bytree': 0.7757858931751904, 'reg_alpha': 0.01581095549321654, 'reg_lambda': 0.07580645279860852, 'FLAML_sample_size': 48093}, 36.39344811439514), 61: ('xgboost', {'n_estimators': 183, 'max_leaves': 517, 'min_child_weight': 0.09633030270457457, 'learning_rate': 0.028084166983832867, 'subsample': 0.825306995670431, 'colsample_bylevel': 0.5421033509522943, 'colsample_bytree': 0.6742025516212758, 'reg_alpha': 0.010703182705824122, 'reg_lambda': 0.18365572197357422, 'FLAML_sample_size': 48093}, 38.97296619415283), 68: ('xgboost', {'n_estimators': 616, 'max_leaves': 89, 'min_child_weight': 0.07082166556325489, 'learning_rate': 0.030323088364337326, 'subsample': 0.8144438946633229, 'colsample_bylevel': 0.5065217282369652, 'colsample_bytree': 0.6351612186749191, 'reg_alpha': 0.10398133070477651, 'reg_lambda': 0.08782946721485667, 'FLAML_sample_size': 48093}, 52.399320125579834)}\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\n",
      "Best Estimator: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.6516269009267046, colsample_bynode=1,\n",
      "              colsample_bytree=0.9343452290229193, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.10941667816856356,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=155,\n",
      "              min_child_weight=0.6891387507484462, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=150, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.002878885335165028, reg_lambda=0.20580189600961715,\n",
      "              scale_pos_weight=1, subsample=0.742890707952142,\n",
      "              tree_method='hist', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=0)\n",
      "\n",
      "Best Configuration: \n",
      "\n",
      "{'n_estimators': 150, 'max_leaves': 155, 'min_child_weight': 0.6891387507484462, 'learning_rate': 0.10941667816856356, 'subsample': 0.742890707952142, 'colsample_bylevel': 0.6516269009267046, 'colsample_bytree': 0.9343452290229193, 'reg_alpha': 0.002878885335165028, 'reg_lambda': 0.20580189600961715, 'FLAML_sample_size': 48093}\n",
      "Best configuration train time: \n",
      "\n",
      "1.0732009410858154\n",
      "\n",
      "Best Iteration\n",
      "68\n",
      "\n",
      "Best loss\n",
      "0.136\n",
      "\n",
      "24.7156662940979\n",
      "{0: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}, 0.13479399681091309), 2: ('rf', {'n_estimators': 4, 'max_features': 0.30151134457776363, 'max_leaves': 4, 'criterion': 'entropy', 'FLAML_sample_size': 10000}, 0.49189019203186035), 3: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954, 'FLAML_sample_size': 10000}, 0.5184452533721924), 4: ('xgboost', {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414, 'FLAML_sample_size': 10000}, 0.5460400581359863), 5: ('xgboost', {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968, 'FLAML_sample_size': 10000}, 0.5750982761383057), 7: ('xgboost', {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 0.8312826637613695, 'learning_rate': 0.4858745329314128, 'subsample': 0.9647550813352507, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931898, 'FLAML_sample_size': 10000}, 0.6475081443786621), 8: ('xgboost', {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 1.6931625792034866, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0016804960453779686, 'reg_lambda': 0.35417434690207034, 'FLAML_sample_size': 10000}, 0.701242208480835), 9: ('xgboost', {'n_estimators': 12, 'max_leaves': 9, 'min_child_weight': 0.8312826637613695, 'learning_rate': 0.38946718731417634, 'subsample': 0.9079647052885418, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931898, 'FLAML_sample_size': 10000}, 0.7403411865234375), 10: ('xgboost', {'n_estimators': 12, 'max_leaves': 27, 'min_child_weight': 1.198219708065302, 'learning_rate': 0.4743416464891248, 'subsample': 0.9418540842995652, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9468117873770695, 'reg_alpha': 0.026629132162083402, 'reg_lambda': 0.4001243226017511, 'FLAML_sample_size': 10000}, 0.8041553497314453), 16: ('xgboost', {'n_estimators': 38, 'max_leaves': 13, 'min_child_weight': 1.424122190564894, 'learning_rate': 0.1738930648110986, 'subsample': 0.9690443404195083, 'colsample_bylevel': 0.8182737361783601, 'colsample_bytree': 0.9018915572644082, 'reg_alpha': 0.008577859051225914, 'reg_lambda': 0.7252401772480003, 'FLAML_sample_size': 10000}, 1.4261832237243652), 21: ('xgboost', {'n_estimators': 38, 'max_leaves': 13, 'min_child_weight': 1.424122190564894, 'learning_rate': 0.1738930648110986, 'subsample': 0.9690443404195083, 'colsample_bylevel': 0.8182737361783601, 'colsample_bytree': 0.9018915572644082, 'reg_alpha': 0.008577859051225914, 'reg_lambda': 0.7252401772480003, 'FLAML_sample_size': 48093}, 2.0317161083221436), 25: ('xgboost', {'n_estimators': 86, 'max_leaves': 92, 'min_child_weight': 0.9746087564319106, 'learning_rate': 0.10086038922566323, 'subsample': 0.9207902955173666, 'colsample_bylevel': 0.7015879783609756, 'colsample_bytree': 0.8442797639004027, 'reg_alpha': 0.005954706988352752, 'reg_lambda': 2.202183653612936, 'FLAML_sample_size': 48093}, 3.3201301097869873), 68: ('xgboost', {'n_estimators': 150, 'max_leaves': 155, 'min_child_weight': 0.6891387507484462, 'learning_rate': 0.10941667816856356, 'subsample': 0.742890707952142, 'colsample_bylevel': 0.6516269009267046, 'colsample_bytree': 0.9343452290229193, 'reg_alpha': 0.002878885335165028, 'reg_lambda': 0.20580189600961715, 'FLAML_sample_size': 48093}, 24.7156662940979)}\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in results:\n",
    "    print(\"Best Estimator: \")\n",
    "    print(\"\")\n",
    "    print(i.model.estimator)\n",
    "    print(\"\")\n",
    "    print(\"Best Configuration: \")\n",
    "    print(\"\")\n",
    "    print(i.best_config)\n",
    "    print(\"Best configuration train time: \")\n",
    "    print(\"\")\n",
    "    print(i.best_config_train_time)\n",
    "    print(\"\")\n",
    "    print(\"Best Iteration\")\n",
    "    print(i.best_iteration)\n",
    "    print(\"\")\n",
    "    print(\"Best loss\")\n",
    "    print(i.best_loss)\n",
    "    print(\"\")\n",
    "    print(i.time_to_find_best_model)\n",
    "    print(i.config_history)\n",
    "    print(\"\")\n",
    "    print(\"////////////////////////////////////////////////////////////////////////////////////////////////////////////\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
